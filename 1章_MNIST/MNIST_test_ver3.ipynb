{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>オライリー本の一章練習中</h1>\n",
    "ドロップアウトによる、精度向上を試みる\n",
    "ドロップアウトでは、全結合層を伝播する値を確率的に伝播させない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from make_tensorboard import make_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>・訓練データとテストデータ読み込み（検証データの割合も設定）</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 訓練用データサンプル数\n",
      "10000 テスト用サンプルデータ数\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1671) #for reproducibility\n",
    "#network and training\n",
    "NB_EPOCH=20\n",
    "BATCH_SIZE=128\n",
    "VERBOSE=1\n",
    "NB_CLASSES=10 #正解ラベルの数\n",
    "OPTIMIZER=SGD() #SGD（確率的勾配降下法を用いる）\n",
    "N_HIDDEN=128 #隠れ層の数\n",
    "VALIDATION_SPLIT=0.2 #交差検定用の検証データを訓練用データから区切る割合\n",
    "DROPOUT=0.3 #ドロップアウトさせる確率の設定\n",
    "\n",
    "#mnistのデータセットを読み込む際に訓練データとテストデータがシャッフルされて振り分けられる\n",
    "#y_trainは訓練用データ（X_train）のラベルを、y_testはテスト用データ（x_test）のラベルを意味する\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "print(X_train.shape[0],'訓練用データサンプル数')\n",
    "print(X_test.shape[0],'テスト用サンプルデータ数')\n",
    "\n",
    "#正解ラベルには「５」などが入っているが、それを0か1のバイナリデータに変換したものをラベルとしなければいけないkerasの仕組み\n",
    "Y_train=np_utils.to_categorical(y_train,NB_CLASSES)\n",
    "Y_test=np_utils.to_categorical(y_test,NB_CLASSES)\n",
    "\n",
    "#X_train（訓練データ）は60000件で、1件分のデータ形式が28*28なので、データを60000件*784の一件あたりの次元数を一次元に整形し直す\n",
    "RESHAPED=784\n",
    "X_train=X_train.reshape(60000,RESHAPED)#784要素の一次元配列に変換\n",
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.reshape(10000,RESHAPED)\n",
    "X_test=X_test.astype('float32')\n",
    "\n",
    "#各要素が0〜1の値の範囲を取るように最大値255で除算し正規化を行う\n",
    "X_train/=255\n",
    "X_test/=255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルの作成</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#10カテゴリに分類するため、出力層は10に設定\n",
    "#出力層の最後にアクティベーション層のフトマックスで正規化\n",
    "model=Sequential()\n",
    "model.add(Dense(N_HIDDEN,input_shape=(RESHAPED,)))#第一引数に出力する数、第二引数（input_shape）に一次元化した配列の要素数である784を設定\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルのコンパイル</h2>\n",
    "<h4>モデルのコンパイルの際にいくつかオプションを与えることができる</h4>\n",
    "<li>モデルの学習時の重み更新に使用する最適化アルゴリズムを選択することができる<br>\n",
    "kerasで使える損失関数にはいくつか種類がある\n",
    "MSE・・・平均二乗誤差（値が0〜１の範囲でなく、正解ラベルとの乖離が大きいと、大きく出力される）\n",
    "バイナリクロスエントロピー・・・2値化分類の際に用いる\n",
    "カテゴリカルクロスエントロピー・・・複数のクラスに対する損失関数を求めることができる。出力はデフォルトでsoftmax関数\n",
    "<li>損失関数を選ぶ必要がある。最適化アルゴリズムが勾配を元に重み空間を最適な方向に導くために使用される<br>\n",
    "<li>学習したモデルを評価する<br>\n",
    "評価には精度、適合率、再現率、（それらを元に調和率）を求められる\n",
    "精度・・・ターゲットに対する正誤\n",
    "適合率・・・選択した項目がどれくらい複数クラス分類に関連しているかを示す\n",
    "再現率・・・複数クラス分類において、特定のクラスに関する精度のいいを示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=OPTIMIZER,#最初の方でSGDを設定済み\n",
    "              metrics=['accuracy'])#精度で評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習過程をファイルとして出力するために別ファイルでTensorBoardを使う関数を定義済\n",
    "callbacks=[make_tensorboard(set_dir_name='MNIST_test')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルの学習を行う</h2>\n",
    "<li>エポック回数の設定<br>\n",
    "学習ごとに損失関数の値を選択された最適化アルゴリズムが最小値にするように重みを調整する\n",
    "<li>バッチサイズ\n",
    "最適化アルゴリズムが重みを更新する際に、データをいくつ使用するか設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 1.7139 - acc: 0.4568 - val_loss: 0.9383 - val_acc: 0.8022\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.9491 - acc: 0.7077 - val_loss: 0.5450 - val_acc: 0.8655\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.7095 - acc: 0.7825 - val_loss: 0.4289 - val_acc: 0.8877\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.6050 - acc: 0.8169 - val_loss: 0.3756 - val_acc: 0.8982\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.5392 - acc: 0.8394 - val_loss: 0.3409 - val_acc: 0.9038\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4910 - acc: 0.8538 - val_loss: 0.3158 - val_acc: 0.9100\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.4616 - acc: 0.8621 - val_loss: 0.2985 - val_acc: 0.9138\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.4358 - acc: 0.8720 - val_loss: 0.2832 - val_acc: 0.9178\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.4164 - acc: 0.8773 - val_loss: 0.2699 - val_acc: 0.9213\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3969 - acc: 0.8819 - val_loss: 0.2595 - val_acc: 0.9253\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3830 - acc: 0.8873 - val_loss: 0.2498 - val_acc: 0.9267\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3682 - acc: 0.8936 - val_loss: 0.2404 - val_acc: 0.9301\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3535 - acc: 0.8955 - val_loss: 0.2334 - val_acc: 0.9313\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3456 - acc: 0.8986 - val_loss: 0.2249 - val_acc: 0.9338\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3323 - acc: 0.9024 - val_loss: 0.2188 - val_acc: 0.9352\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3213 - acc: 0.9051 - val_loss: 0.2119 - val_acc: 0.9375\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3137 - acc: 0.9072 - val_loss: 0.2059 - val_acc: 0.9393\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3058 - acc: 0.9116 - val_loss: 0.2004 - val_acc: 0.9415\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2977 - acc: 0.9123 - val_loss: 0.1959 - val_acc: 0.9430\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2898 - acc: 0.9159 - val_loss: 0.1904 - val_acc: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c30ae55c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#バッチサイズ、エポック回数は最初の方に設定済\n",
    "model.fit(X_train,Y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCH,callbacks=callbacks,verbose=VERBOSE,validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルのテストを行う</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test,verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.19377726282924412\n",
      "test accuracy: 0.9426\n"
     ]
    }
   ],
   "source": [
    "print(\"test score:\",score[0])\n",
    "print(\"test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドロップアウトによって、各ニューロンは近傍のニューロンを頼れなくなるため、各ニューロンが賢くなる\n",
    "評価の際にはドロップアウトをもちいらないのは、学習で優れたニューロンを構築できたため"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
